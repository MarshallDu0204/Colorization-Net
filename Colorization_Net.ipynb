{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colorization_Net.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdqopooJRKS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2670c07b-fabe-417f-d416-68bafff28630"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNUqQioZSGdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22813227-db26-4af0-e37d-51f8a681ade7"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from keras import Input, Model\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input, decode_predictions\n",
        "from keras.layers import UpSampling2D, RepeatVector, Reshape, concatenate\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from keras.utils import generic_utils\n",
        "\n",
        "resnet = InceptionResNetV2(weights=None, include_top=True)\n",
        "def getImgList(basePath = '/content/drive/My Drive/Colab Notebooks/colordata/'):\n",
        "    imgList1 = os.listdir(basePath + '1/')\n",
        "    newimgList1 = []\n",
        "    for item in imgList1:\n",
        "        newimgList1.append(basePath + '1/' + item)\n",
        "    \n",
        "    imgList2 = os.listdir(basePath + '2/')\n",
        "    newimgList2 = []\n",
        "    for item in imgList2:\n",
        "        newimgList2.append(basePath + '2/' + item)\n",
        "    \n",
        "    imgList3 = os.listdir(basePath + '3/')\n",
        "    newimgList3 = []\n",
        "    for item in imgList3:\n",
        "        newimgList3.append(basePath + '3/' + item)\n",
        "    \n",
        "    imgList4 = os.listdir(basePath + '4/')\n",
        "    newimgList4 = []\n",
        "    for item in imgList4:\n",
        "        newimgList4.append(basePath + '4/' + item)\n",
        "    return newimgList1 + newimgList2 + newimgList3 + newimgList4\n",
        "\n",
        "def loadWeight(basePath = '/content/drive/My Drive/Colab Notebooks/model/'):\n",
        "    resnet.load_weights(basePath + 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "    print(\"Resnet Weight loaded success\")\n",
        "\n",
        "def convImg(dataList, channels):\n",
        "    imgList = []\n",
        "    for img in dataList:\n",
        "        img = cv2.resize(img, (256, 256))\n",
        "        label_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        if channels == 1:\n",
        "            label_img = label_img[:, :, 0]\n",
        "        imgList.append(label_img)\n",
        "    \n",
        "    return np.array(imgList).reshape(len(dataList), 256, 256, channels)\n",
        "\n",
        "def resnetEmbedding(dataList):\n",
        "    imgData = []\n",
        "    for img in dataList:\n",
        "        img = cv2.resize(img, (299, 299))\n",
        "        greyImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        bgrImg = cv2.cvtColor(greyImg, cv2.COLOR_GRAY2BGR)\n",
        "        bgrImg = preprocess_input(bgrImg)\n",
        "        imgData.append(bgrImg)\n",
        "    imgData = np.array(imgData, dtype=float)\n",
        "    embedding = resnet.predict(imgData)\n",
        "    return embedding\n",
        "\n",
        "def preReadData(dataList):  #fix the colab drive read issue\n",
        "    allData = []\n",
        "    for item in tqdm(dataList):\n",
        "        img = cv2.imread(item)\n",
        "        allData.append(img)\n",
        "    return allData\n",
        "\n",
        "def getData(allData, batch_size, train=True):\n",
        "    allData = allData[:24800]\n",
        "    while True:\n",
        "        for i in range(0, len(allData), batch_size):\n",
        "            img = convImg(allData[i:i+batch_size], 3)\n",
        "            embeddingImg = resnetEmbedding(allData[i:i+batch_size])\n",
        "            x = 2 * img[:, :, :, 0] / 100 - 1\n",
        "            x = x.reshape(x.shape + (1,))\n",
        "            y = img[:, :, :, 1:] / 127\n",
        "            yield([x, embeddingImg], y)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUAv3SWy98IY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c0451a7-ea10-46a0-b281-24d0d77b670b"
      },
      "source": [
        "def colorNet():\n",
        "    embedInput = Input(shape=(1000,))\n",
        "    encoderInput = Input(shape=(256, 256, 1,))\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(encoderInput)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "    fushionX = RepeatVector(32 * 32)(embedInput)\n",
        "    fushionX = Reshape(([32, 32, 1000]))(fushionX)\n",
        "    fushionX = concatenate([x, fushionX], axis=3)\n",
        "\n",
        "    x = Conv2D(256, (1, 1), activation='relu', padding='same')(fushionX)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2D(2, (3, 3), activation='relu', padding='same')(x)\n",
        "    result = UpSampling2D((2, 2))(x)\n",
        "\n",
        "    model =  Model(inputs = [encoderInput, embedInput], outputs = result)\n",
        "    model_optimizer = tf.keras.optimizers.Adam(0.001)\n",
        "    model.compile(optimizer=model_optimizer, loss='mse', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "modelPath = '/content/drive/My Drive/Colab Notebooks/model/colorNet.hdf5'\n",
        "model = colorNet()\n",
        "\n",
        "if os.path.exists(modelPath):\n",
        "    model.load_weights(modelPath)\n",
        "    print(\"Check point loaded!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check point loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMVAtcFLDnQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loadWeight()\n",
        "allData = preReadData(getImgList())\n",
        "allData = np.asarray(allData)\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/data.npy',allData)\n",
        "allData = np.load('/content/drive/My Drive/Colab Notebooks/data.npy')\n",
        "r_epochs = 0\n",
        "epoch_length = 248\n",
        "num_epochs = 100\n",
        "dataGen = getData(allData,100)\n",
        "bestLoss = np.Inf\n",
        "iter_num = 0\n",
        "losses = np.zeros((epoch_length, 2))\n",
        "for epoch_num in range(num_epochs):\n",
        "    progbar = generic_utils.Progbar(epoch_length)\n",
        "    print('Epoch {}/{}'.format(r_epochs + 1, num_epochs))\n",
        "    r_epochs += 1\n",
        "    while True:\n",
        "        X,Y = next(dataGen)\n",
        "        modelLoss = model.train_on_batch(X,Y)\n",
        "        losses[iter_num, 0] = modelLoss[0]\n",
        "        losses[iter_num, 1] = modelLoss[1]\n",
        "        \n",
        "        iter_num += 1\n",
        "        progbar.update(iter_num, [('loss', np.mean(losses[:iter_num, 0])), ('acc', np.mean(losses[:iter_num, 1]))])\n",
        "        if iter_num == epoch_length:\n",
        "            if modelLoss[0] < bestLoss:\n",
        "                model.save_weights(modelPath)\n",
        "            iter_num = 0\n",
        "            break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxKw7npUAGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loadWeight()\n",
        "def test():\n",
        "    outputPath = '/content/drive/My Drive/Colab Notebooks/test/'\n",
        "    testImg = os.listdir('/content/drive/My Drive/Colab Notebooks/testdata/')\n",
        "    allData = []\n",
        "    for item in testImg:\n",
        "        basePath = '/content/drive/My Drive/Colab Notebooks/testdata/'\n",
        "        img = cv2.imread(basePath + item)\n",
        "        allData.append(img)\n",
        "    greyImg = convImg(allData,1)\n",
        "    processImg = 2 * greyImg / 100 - 1\n",
        "    imgEmbed = resnetEmbedding(allData)\n",
        "    result = model.predict([processImg,imgEmbed])\n",
        "    for i in range(len(result)):\n",
        "        combine = np.zeros((256, 256, 3))\n",
        "        combine[:, :, 0] = greyImg[i][:, :, 0]\n",
        "        combine[:, :, 1:] = result[i] * 127\n",
        "        imgCopy = np.uint8(combine)\n",
        "        cv2.imwrite(outputPath + 'test_img'+str(i)+'.jpg',cv2.cvtColor(imgCopy, cv2.COLOR_LAB2BGR))\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}